{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9a3a9f",
   "metadata": {},
   "source": [
    "# OpenCV program for image differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afec1bb6",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Run the program from the exercise material and see if shows the expected results? Try to move your hands in front of the camera and try to move the camera and see the effects on the difference image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357b8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting image capture\n",
      "Opening connection to camera\n",
      "Starting camera loop\n",
      "Stopping image loop\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_in_moved_window(win_name, img, x, y):\n",
    "    \"\"\"\n",
    "    Show an image in a window, where the position of the window can be given\n",
    "    \"\"\"\n",
    "    cv2.namedWindow(win_name)\n",
    "    cv2.moveWindow(win_name, x, y)\n",
    "    cv2.imshow(win_name,img)\n",
    "\n",
    "\n",
    "def capture_from_camera_and_show_images():\n",
    "    print(\"Starting image capture\")\n",
    "\n",
    "    print(\"Opening connection to camera\")\n",
    "    url = 0\n",
    "    use_droid_cam = False\n",
    "    if use_droid_cam:\n",
    "        url = \"http://192.168.1.120:4747/video\"\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    # cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "\n",
    "    print(\"Starting camera loop\")\n",
    "    # Get first image\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame\")\n",
    "        exit()\n",
    "\n",
    "    # Transform image to gray scale and then to float, so we can do some processing\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "\n",
    "    # To keep track of frames per second\n",
    "    start_time = time.time()\n",
    "    n_frames = 0\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        ret, new_frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "\n",
    "        # Transform image to gray scale and then to float, so we can do some processing\n",
    "        new_frame_gray = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "\n",
    "        # Compute difference image\n",
    "        dif_img = np.abs(new_frame_gray - frame_gray)\n",
    "\n",
    "        # Keep track of frames-per-second (FPS)\n",
    "        n_frames = n_frames + 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = int(n_frames / elapsed_time)\n",
    "\n",
    "        # Put the FPS on the new_frame\n",
    "        str_out = f\"fps: {fps}\"\n",
    "        font = cv2.FONT_HERSHEY_COMPLEX\n",
    "        cv2.putText(new_frame, str_out, (100, 100), font, 1, 255, 1)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        show_in_moved_window('Input', new_frame, 0, 10)\n",
    "        show_in_moved_window('Input gray', new_frame_gray.astype(np.uint8), 600, 10)\n",
    "        show_in_moved_window('Difference image', dif_img.astype(np.uint8), 1200, 10)\n",
    "\n",
    "        # Old frame is updated\n",
    "        frame_gray = new_frame_gray\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            stop = True\n",
    "\n",
    "    print(\"Stopping image loop\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    capture_from_camera_and_show_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dfb34",
   "metadata": {},
   "source": [
    "# Change detection by background subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3321b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting image capture\n",
      "Opening connection to camera\n",
      "Starting camera loop\n",
      "Stopping image loop\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_in_moved_window(win_name, img):\n",
    "    \"\"\"\"\n",
    "    Show an image in a window, there the position of the\n",
    "    window can be given\n",
    "    \n",
    "    \"\"\"\n",
    "    cv2.namedWindow(win_name)\n",
    "    #cv2.moveWindow(win_name, x, y)\n",
    "    cv2.imshow(win_name, img)\n",
    "\n",
    "def add_text(image, text, org, color):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 1\n",
    "    image = cv2.putText(image, text, org, font, fontScale, color)\n",
    "    return image\n",
    "    \n",
    "def capture_from_camera_and_show_images():\n",
    "    alpha=0.98\n",
    "    T=20\n",
    "    A=20\n",
    "    print(\"Starting image capture\")\n",
    "    \n",
    "    print(\"Opening connection to camera\")\n",
    "    url=0\n",
    "    use_droid_cam=False\n",
    "    if use_droid_cam:\n",
    "        url=\"http://192.168.1.120:4747/video\"\n",
    "    cap=cv2.VideoCapture(url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "    \n",
    "    print(\"Starting camera loop\")\n",
    "    # Get first image\n",
    "    ret, frame=cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame\")\n",
    "        exit()\n",
    "        \n",
    "    # Transform image to gray scale and then to float, so we can do some processing\n",
    "    frame_gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    \n",
    "    # To keep track of the frames per second\n",
    "    start_time=time.time()\n",
    "    n_frames=0\n",
    "    stop=False\n",
    "    while not stop:\n",
    "        ret, new_frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame. Exiting...\")\n",
    "            break\n",
    "        # Transform image to gray scale and then to float, so we can do some processing\n",
    "        new_frame_gray= cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "        \n",
    "        # Compute difference image\n",
    "        dif_img = np.abs(new_frame_gray- frame_gray)\n",
    "        \n",
    "        # Create a binary image \n",
    "        ret,thresh1 = cv2.threshold(dif_img,T,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Computes the total number of foreground, F, pixels in the foreground image.\n",
    "        F = np.count_nonzero(thresh1)\n",
    "        totalF = thresh1.size\n",
    "        F_percentage = F/totalF*100\n",
    "        \n",
    "        # Set an alarm\n",
    "        if F_percentage>A:\n",
    "            print(f\"Change Detected! Has changed {F_percentage}% of the foreground\")\n",
    "        \n",
    "        # Get some stats\n",
    "        max_value = np.max(dif_img)\n",
    "        min_value = np.min(dif_img)\n",
    "        mean_value = np.mean(dif_img)\n",
    "        \n",
    "        \n",
    "        # Draw text\n",
    "        text1 = \"Max value = \" + str(max_value)\n",
    "        text2 = \"Min value = \" + str(min_value)\n",
    "        text3 = \"Number of pixel changed = \" + str(F_percentage)\n",
    "        text4 = \"Mean value = \" + str(mean_value)\n",
    "        \n",
    "        org1 = (10, 30)\n",
    "        org2 = (10, 60)\n",
    "        org3 = (10, 90)\n",
    "        org4 = (10, 120)\n",
    "\n",
    "        color = (245, 245, 245)\n",
    "        dif_img = add_text(dif_img, text1, org1, color)\n",
    "        dif_img = add_text(dif_img, text2, org2, color)\n",
    "        dif_img = add_text(dif_img, text3, org3, color)\n",
    "        dif_img = add_text(dif_img, text4, org4, color)\n",
    "        \n",
    "        # Show the images\n",
    "        #show_in_moved_window('Input', new_frame)\n",
    "        #show_in_moved_window('Background', new_frame_gray.astype(np.uint8))\n",
    "        show_in_moved_window('Difference image', dif_img.astype(np.uint8))\n",
    "        show_in_moved_window('Binary image', thresh1.astype(np.uint8))\n",
    "        \n",
    "        # Old frame is updated\n",
    "        frame_gray=alpha*frame_gray+(1-alpha)*new_frame_gray\n",
    "        \n",
    "        # Stop the loop is key 'q' is pressed\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            stop = True\n",
    "    print(\"Stopping image loop\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    capture_from_camera_and_show_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
